{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f1929-612c-4b72-9b30-20b79acaade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed number for repeatability\n",
    "ranosedo = 2\n",
    "from numpy.random import seed\n",
    "seed(ranosedo)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(ranosedo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c0b01-93a0-4925-aacc-b314ca9ac18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from numba import cuda, jit, njit\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aca4d1-30a5-4cea-8651-50b36504f45e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocessingfunctions import *\n",
    "from ResNet3D import Resnet3DBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483cc5f6-3d77-48fc-8c74-3fe91f744d0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769c6a9-c564-4b2b-a2e8-012ac7d273fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "prefetch_size = len(df_val)\n",
    "\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((np.array([process_scan(path) for path in df_train['FILEPATH']]),\n",
    "                                                   np.array([label for label in df_train['labels']]))) #create a dataframe containing the training files with labels indicating the two classes\n",
    "\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((np.array([process_scan(path) for path in df_val['FILEPATH']]),\n",
    "                                                   np.array([label for label in df_val['labels']]))) #create a dataframe containing the validation files with labels indicating the two classes\n",
    "# Augment on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(df_train))\n",
    "        .map(train_preprocessing)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(prefetch_size)\n",
    ")\n",
    "\n",
    "#iterator for training batch\n",
    "iterator_t = tf.compat.v1.data.make_one_shot_iterator(train_dataset)\n",
    "next_element_train = iterator_t.get_next()\n",
    "\n",
    "# Only rescale for validation set.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(df_val))\n",
    "        .map(validation_preprocessing)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(prefetch_size)\n",
    ")\n",
    "\n",
    "#iterator for validation batch\n",
    "iterator_v = tf.compat.v1.data.make_one_shot_iterator(validation_dataset)\n",
    "next_element_validate = iterator_v.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d8451-d311-4a8c-a540-ebe11cd53465",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Transfer learning: Retrain a pretrained model with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d795d-566a-45c1-9099-62cc0332b9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'ResNet.h5'\n",
    "old_model = tf.keras.models.load_model('ResNet.h5')\n",
    "input_volume_size = tf.keras.Input((final_height, final_width, final_depth, 1)) #specify the final_height, final_width, final_depth\n",
    "\n",
    "regularization_factor = 1e-16\n",
    "model = Resnet3DBuilder.build_resnet_18((final_height, final_width, final_depth, 1),1,regularization_factor)\n",
    "\n",
    "def updateweights(model, old_model):\n",
    "    for layer, old_layer in zip(model.layers[1:], old_model.layers[1:]):\n",
    "        try:\n",
    "            layer.set_weights(old_layer.get_weights())\n",
    "        except:\n",
    "            print(\"Weights transfer failed! for layer {}\".format(layer.name))\n",
    "    return model\n",
    "\n",
    "model = updateweights(model,old_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be5ad2-035c-4be2-b4c6-8af4b5299af3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525d8bc-91b5-42ff-a479-4423c263bd76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "config = tf.compat.v1.ConfigProto( device_count={'GPU':0})\n",
    "config.gpu_options.allow_growth = True \n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "initial_learning_rate = 1e-5\n",
    "wandb.init(project=\"Classifier\",name='20220604_MainRun_121x145x121')\n",
    "\n",
    "\n",
    "metricr = 'accuracy'\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                          decay_steps=100000000000,\n",
    "                                                          decay_rate=0.99,\n",
    "                                                          staircase=True,\n",
    "                                                            )\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.999, epsilon=1e-18, amsgrad = True),\n",
    "    metrics=[metricr],\n",
    ")\n",
    "\n",
    "\n",
    "model.run_eagerly = True\n",
    "\n",
    "epochs = 300\n",
    "checkpoint_filepath =  '/mnt/j6/m258195/python_m258195/1style_transfer/Custom/checkpoints/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_filepath)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = checkpoint_filepath,\n",
    "                                                monitor = metricr,\n",
    "                                                verbose = 2,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_freq = 'epoch',\n",
    "                                                save_best_only=True,\n",
    "                                                mode = 'max')\n",
    "\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=metricr, patience=int(epochs/2))\n",
    "\n",
    "model.save_weights(checkpoint_filepath.format(epoch=0))\n",
    "print('Trainig begins...')\n",
    "model_run = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    batch_size = batch_size*8,\n",
    "    callbacks=[WandbCallback(),checkpoint_cb],\n",
    ")\n",
    "\n",
    "model.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
